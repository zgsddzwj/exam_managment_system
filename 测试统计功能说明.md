# 测试统计功能说明

## ✅ 已实现的功能

### 1. 测试次数统计

**实现方式：**
- 每次学生点击"测试"按钮时，系统会创建一个 `TestAttempt` 记录
- 记录包含：
  - 任务ID
  - 学生ID
  - 代码内容
  - 编程语言
  - 测试结果（JSON格式）
  - 测试时间

**统计逻辑：**
- 学生提交代码时，系统会统计该学生对该任务的所有测试次数
- 统计方式：`TestAttempt.objects.filter(task=task, student=user).count()`
- 统计结果保存在 `Submission.test_count` 字段中

**显示位置：**
1. 提交详情页面 (`/submissions/:id`)
2. 提交列表页面 (`/submissions`)
3. 成绩导出（Excel/CSV）

### 2. 执行时间统计

**实现方式：**
- 提交代码时，系统会记录执行所有测试用例（包括隐藏测试）的总时间
- 统计的是代码实际执行的时间，从开始执行到所有测试完成的时间

**统计逻辑：**
```python
start_time = time.time()
# ... 执行所有测试用例 ...
total_time = time.time() - start_time
```

**显示位置：**
1. 提交详情页面 (`/submissions/:id`)
2. 提交列表页面 (`/submissions`)
3. 成绩导出（Excel/CSV）

### 3. 错误信息显示

**实现方式：**
- 每个测试用例的执行结果都会记录错误信息
- 错误信息包括：
  - 编译错误 (`compile_output`)
  - 运行时错误 (`stderr`)
  - 其他错误 (`error`)

**显示位置：**
- 提交详情页面会显示每个测试用例的错误信息（如果有）

## 📊 数据库模型

### TestAttempt（测试尝试记录）
用于记录每次测试：
- `task`: 任务
- `student`: 学生
- `code_content`: 测试时的代码内容
- `language`: 编程语言
- `test_results`: 测试结果（JSON）
- `created_at`: 测试时间

### Submission（提交记录）
包含统计信息：
- `test_count`: 测试次数（从TestAttempt统计）
- `total_time`: 总执行时间（秒）
- `score`: 得分

## 🔍 代码位置

### 后端
- **模型定义**: `backend/submissions/models.py`
  - `TestAttempt` 类（第72-99行）
  - `Submission` 类（第8-39行）

- **测试逻辑**: `backend/submissions/views.py`
  - `test_code()` 函数（第21-99行）：记录每次测试
  - `submit_code()` 函数（第102-210行）：统计测试次数和执行时间

### 前端
- **提交详情**: `frontend/src/pages/SubmissionDetail.tsx`
  - 显示测试次数（第92行）
  - 显示总耗时（第95行）
  - 显示错误信息（第160-174行）

- **提交列表**: `frontend/src/pages/SubmissionList.tsx`
  - 显示测试次数和耗时

## 📝 注意事项

### 测试次数统计
- ✅ **已实现**：每次点击"测试"按钮都会记录
- ✅ **统计准确**：提交时统计该任务的所有测试次数

### 执行时间统计
- ⚠️ **当前实现**：只统计提交时执行所有测试用例的时间
- ⚠️ **不包含**：学生编写代码、思考、多次测试之间的时间间隔
- 💡 **说明**：这是代码实际执行时间，不是学生花费的总时间

### 如果需要统计学生总时间
如果需要统计学生从开始到提交的总时间，需要：
1. 记录学生第一次访问任务页面的时间
2. 记录学生提交的时间
3. 考虑页面刷新、离开等复杂情况

当前实现更适合统计代码执行性能，而不是学习时间。

## ✅ 总结

**测试次数统计：✅ 完全实现**
- 每次测试都会记录
- 提交时会统计总数
- 前端和导出功能都有显示

**执行时间统计：✅ 部分实现**
- 统计代码执行时间
- 不统计学生编写代码的总时间

**错误信息显示：✅ 完全实现**
- 所有错误都会记录和显示

